{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 02 Objectives"
      ],
      "metadata": {
        "id": "5_JnAIYaIJV-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VSU37NhzAEhp"
      },
      "outputs": [],
      "source": [
        "# Objective 1: Computationally verify that NLL is equivalent to cross entropy of one-hot label\n",
        "\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss, Softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = torch.tensor([1]) # note that target for cel should contain the labels, not the one_hot\n",
        "input_ = torch.tensor([[3.2, 5.3]]) # note that input_ should be logits before softmax for CrossEntropyLoss\n",
        "cel = CrossEntropyLoss()\n",
        "softmax = Softmax(dim=1) # softmax to second dimension\n",
        "out1 = cel(input_, target)\n",
        "out2 = -softmax(input_)[0, 1].log() # YOUR CODE GOES HERE(NLL) (likelihood = probability)\n",
        "\n",
        "# show CE and NLL is equivalent\n",
        "print(out1, out2)\n",
        "assert (out1-out2).abs() < 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_04sxZfAR-4",
        "outputId": "42a220b3-d219-46ac-99ea-9f8bf378b986"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1155) tensor(0.1155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 2: Use a space tokenizer to create a vocab from a text list and map each text to vocab ids\n",
        "text_list = [\"Hello world\", \"Hi world\", \"Hello cute puppy\"]\n",
        "vocab = ['<UNK>'] + sorted(set(word for text in text_list for word in text.split())) # further splited by white space and remove redundancy by making it a set\n",
        "print(vocab)\n",
        "token2idx = {word: id for id, word in enumerate(vocab)} # dictionary\n",
        "print(token2idx)\n",
        "\n",
        "def text2ids(text):\n",
        "  tokens = text.split() # list of tokens\n",
        "  ids = tuple(token2idx[token] if token in token2idx else 0 for token in tokens) # YOUR CODE GOES HERE\n",
        "  return ids\n",
        "\n",
        "assert text2ids(text_list[0]) == (1, 5) # If text is Hello world"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbz2jSJkAh3u",
        "outputId": "f3cdac34-2328-4cb3-e7d0-169a6d57fb07"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<UNK>', 'Hello', 'Hi', 'cute', 'puppy', 'world']\n",
            "{'<UNK>': 0, 'Hello': 1, 'Hi': 2, 'cute': 3, 'puppy': 4, 'world': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 3: Verify that a linear layer on top of the one-hot vectors is equivalent to PyTorch nn.Embedding\n",
        "import torch\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "labels = torch.tensor([1]) # check the one_hot representation\n",
        "one_hot_labels = one_hot(labels, num_classes=3)\n",
        "print(labels, one_hot_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3sLsLqaEqMC",
        "outputId": "55349cbf-0464-46f6-ff77-76fedb7b41b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1]) tensor([[0, 1, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Embedding # simple lookup table -> just indexing\n",
        "embedding = Embedding(3, 4) # embedding.weight (3, 4 is the size of embedding)\n",
        "emb1 = embedding(labels)\n",
        "emb2 = one_hot_labels.float() @ embedding.weight # YOUR CODE GOES HERE (@ indicates matrix multiplication)\n",
        "print(emb1, emb2)\n",
        "assert (emb1-emb2).abs().sum() < 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWN_-_yEGIda",
        "outputId": "14e8c703-9062-4dcf-8738-85244ecd2720"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0534, -1.3070, -1.2955,  0.8091]], grad_fn=<EmbeddingBackward0>) tensor([[ 0.0534, -1.3070, -1.2955,  0.8091]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 4: Create a simple recurrent neural network with tanh activation\n",
        "import torch\n",
        "from torch.nn import Linear, Tanh\n",
        "torch.manual_seed(605)\n",
        "batch_size = 3\n",
        "hidden_size = input_size = 4\n",
        "\n",
        "layer = None # YOUR CODE GOES HERE\n",
        "activation = Tanh()\n",
        "\n",
        "h_prev = torch.randn([batch_size, hidden_size])\n",
        "x_cur = torch.randn([batch_size, hidden_size])\n",
        "h_cur = activation(layer(torch.cat([h_prev, x_cur], dim=1)))\n",
        "assert h_cur.size() == (batch_size, hidden_size)"
      ],
      "metadata": {
        "id": "rZDWYoYAGW2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApWVym33JFLD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}