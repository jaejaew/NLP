{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWVTRgRmHkYk",
        "outputId": "4f25ec00-2b38-4604-fd1f-1d2781081fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n"
          ]
        }
      ],
      "source": [
        "# Objective 1: Print \"Hello World\" in CoLab\n",
        "print(\"Hello World!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFPIOn2dOOZh",
        "outputId": "5f9348c7-27a7-4481-8734-e92218236059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 13 05:25:31 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eglChPAhHrqc",
        "outputId": "4e125dac-cc61-4f03-8b2a-e261e8e655ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.1412, -1.1903, -0.2589],\n",
            "        [ 0.0178,  0.4158,  0.0207]])\n",
            "tensor([[-0.9021,  0.3112,  0.1275, -0.3989, -1.2741],\n",
            "        [ 1.2167, -2.5898,  1.5967, -1.8627,  1.0125],\n",
            "        [-1.5573, -0.0671,  0.4498, -0.5815, -0.5709]])\n"
          ]
        }
      ],
      "source": [
        "# Objective 2: Perform matrix multiplication in PyTorch\n",
        "import torch\n",
        "\n",
        "# it is always a good idea to start with a random seed\n",
        "torch.manual_seed(605)\n",
        "\n",
        "a = torch.randn(2, 3)\n",
        "b = torch.randn(3, 5)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6BmkJGDICEJ",
        "outputId": "24321abc-27e8-4ea4-f0be-c51e999307bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5])\n",
            "tensor([[-2.0745,  3.4550, -1.8714,  1.9125, -2.5113],\n",
            "        [ 0.4577, -1.0728,  0.6755, -0.7937,  0.3865]])\n"
          ]
        }
      ],
      "source": [
        "c = a.matmul(b)\n",
        "print(c.size())\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_c11lamIID0",
        "outputId": "57f8c9e4-1104-4c6f-ef79-44ad8bdf400e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "Parameter containing:\n",
            "tensor([[-0.0950,  0.2956,  0.3553],\n",
            "        [ 0.2678, -0.0171, -0.4928],\n",
            "        [-0.1845, -0.2508,  0.2816],\n",
            "        [ 0.3971, -0.2691, -0.0812],\n",
            "        [ 0.2856, -0.1239,  0.1443]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Often times, we want to paramterize b, which means we want to treat it as a variable than an input.\n",
        "from torch import nn\n",
        "# if bias=True (default), a bias vector is added\n",
        "b_layer = nn.Linear(3, 5, bias=False)\n",
        "# Note that linear weight is trasponsed because it is applied at the front instead of at the back.\n",
        "print(b_layer.weight.size()) # have to reverse the size from (3, 5) <- because of the way of multiplication\n",
        "print(b_layer.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM1ONJKyJBuC",
        "outputId": "d79b9e15-c1d2-4a4e-b09c-91a8e6b1ed16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5523,  0.4535,  0.0151,  0.7945,  0.4361],\n",
            "        [ 0.1286, -0.0126, -0.1018, -0.1065, -0.0435]], grad_fn=<MmBackward0>)\n",
            "tensor([[-0.5523,  0.4535,  0.0151,  0.7945,  0.4361],\n",
            "        [ 0.1286, -0.0126, -0.1018, -0.1065, -0.0435]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "c_1 = b_layer(a) # b_layer.weight multiply by a is stored in c_1, input is a\n",
        "# use .t() for transposing the matrix\n",
        "c_2 = a.matmul(b_layer.weight.t())\n",
        "print(c_1)\n",
        "print(c_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfaM76N-J3kT",
        "outputId": "8f1f657b-8364-4ccf-c4c1-f3917adfd2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "tensor([[ 1.1589, -0.7744, -0.2382],\n",
            "        [ 1.1589, -0.7744, -0.2382],\n",
            "        [ 1.1589, -0.7744, -0.2382],\n",
            "        [ 1.1589, -0.7744, -0.2382],\n",
            "        [ 1.1589, -0.7744, -0.2382]])\n"
          ]
        }
      ],
      "source": [
        "# Objective 3: Perform differentiation in PyTorch\n",
        "y = c_1.sum() #\n",
        "y.backward()\n",
        "print(b_layer.weight.grad.size())\n",
        "print(b_layer.weight.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQT1jL5SKpB6",
        "outputId": "dec30317-125b-4129-dc84-e7b678a3b466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5600, -0.8451],\n",
            "        [-0.0089, -0.2796],\n",
            "        [-0.1985,  0.0163],\n",
            "        [ 0.1583,  0.3016],\n",
            "        [ 0.1275, -0.3969]])\n"
          ]
        }
      ],
      "source": [
        "# Objective 4: Create a soft XOR dataset\n",
        "# N is the size of the dataset\n",
        "N = 5\n",
        "# First, create inputs\n",
        "x = torch.rand(N, 2) * 2.0 - 1.0\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y36y6y_WMbTf",
        "outputId": "4c6cf540-5306-4078-e589-f313178f2333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ True,  True],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False],\n",
            "        [False, False]])\n",
            "tensor([False, False, False, False, False])\n"
          ]
        }
      ],
      "source": [
        "# Now, given the inputs, create labels\n",
        "z = x.round().bool()\n",
        "print(z)\n",
        "y = z[:, 0].logical_xor(z[:, 1])\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4-Sa1hVUNIrZ"
      },
      "outputs": [],
      "source": [
        "# Objective 5: Create a two-layer neural network for the dataset\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# simple XOR dataset\n",
        "X = torch.Tensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = torch.Tensor([[0, 1, 1, 0]]).view(-1, 1) # make calumn vector\n",
        "\n",
        "\n",
        "class TwoLayerNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(TwoLayerNN, self).__init__()\n",
        "    self.lin1 = nn.Linear(2, 3) # input tensor has dimension of 2, size of hidden layer is 3\n",
        "    self.lin2 = nn.Linear(3, 1) # output dim: 1 (T/F)\n",
        "\n",
        "  def forward(self, x): # mandatory when using nn.Module\n",
        "    x = self.lin1(x)\n",
        "    x = F.sigmoid(x) # put the nonlinearity\n",
        "    out = self.lin2(x)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_Q-BaJ7Bfkp9"
      },
      "outputs": [],
      "source": [
        "model = TwoLayerNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi3VDvoxfkp9",
        "outputId": "2ba325bf-ca23-4d71-be19-9b403eef5dc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0691], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model(torch.Tensor([1, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uAXJcMG2fkp9"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QNiGIVpafkp-"
      },
      "outputs": [],
      "source": [
        "def weight_init(model):\n",
        "\tfor m in model.modules(): # find layer\n",
        "\t\tif isinstance(m, nn.Linear):\n",
        "\t\t\tm.weight.data.normal_(0, 1) # mean, std\n",
        "\n",
        "weight_init(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOm7uPPlfkp-",
        "outputId": "9da154d5-6ce3-40a3-ba20-fc06dc0f8d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.5289431810379028\n",
            "Epoch: 500, Loss: 4.747619186673546e-09\n",
            "Epoch: 1000, Loss: 8.881784197001252e-14\n",
            "Epoch: 1500, Loss: 2.2737367544323206e-13\n",
            "Epoch: 2000, Loss: 1.2789769243681803e-13\n"
          ]
        }
      ],
      "source": [
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "epochs = 2001\n",
        "steps = X.size(0)\n",
        "for i in range(epochs):\n",
        "\tfor j in range(steps):\n",
        "\t\tindex = np.random.randint(X.size(0))\n",
        "\t\tx_var = Variable(X[index], requires_grad=False) # X, Y with same index!\n",
        "\t\ty_var = Variable(Y[index], requires_grad=False)\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\ty_hat = model(x_var) # forward propagation\n",
        "\t\tloss = loss_func(y_hat, y_var)\n",
        "\t\tloss.backward() # compute all gradients of the computational graph\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\tif i%500 == 0:\n",
        "\t\tprint(f'Epoch: {i}, Loss: {loss.data.numpy()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iefKQOJMfkp-",
        "outputId": "47a121f0-c4fd-458c-c055-24a9c58726bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.5763e-07], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model(torch.Tensor([1, 1]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "5984c07bd85a09704efeebc43c280456997f3d9e1810f10980d19f89f173e200"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}